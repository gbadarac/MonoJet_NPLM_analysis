Initial weights: [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]
w_i_init_torch: tensor([ 0.0335, -0.0388,  0.0471,  0.0249,  0.0396,  0.0422, -0.0415,  0.0345,
         0.0335,  0.0421,  0.0159,  0.0254,  0.0412, -0.0263,  0.0483,  0.0402,
        -0.0398, -0.0308,  0.0316,  0.0433,  0.0466, -0.0242, -0.0349, -0.0321,
        -0.0359,  0.0521, -0.0306,  0.0335,  0.0377,  0.0171],
       dtype=torch.float64, requires_grad=True)
Attempt 1: Optimization failed with error: list index out of range
w_i_init_torch: tensor([ 0.0212,  0.0213,  0.0234, -0.0226,  0.0116, -0.0204,  0.0333, -0.0333,
        -0.0148, -0.0367,  0.0338, -0.0349,  0.0381, -0.0419, -0.0331,  0.0342,
         0.0476, -0.0419,  0.0300,  0.0282,  0.0578, -0.0168, -0.0326,  0.0413,
        -0.0503, -0.0312,  0.0381, -0.0288, -0.0347,  0.0294],
       dtype=torch.float64, requires_grad=True)
Attempt 2: Optimization failed with error: list index out of range
w_i_init_torch: tensor([ 0.0339, -0.0429, -0.0305, -0.0181, -0.0437,  0.0259,  0.0401, -0.0495,
         0.0255, -0.0297, -0.0382,  0.0396,  0.0504,  0.0356,  0.0264, -0.0219,
        -0.0250, -0.0276, -0.0348, -0.0236, -0.0296, -0.0481, -0.0374,  0.0376,
         0.0331,  0.0211,  0.0319, -0.0302,  0.0283,  0.0221],
       dtype=torch.float64, requires_grad=True)
Attempt 3: Optimization failed with error: list index out of range
w_i_init_torch: tensor([ 0.0221, -0.0384,  0.0378,  0.0210, -0.0188,  0.0265, -0.0454, -0.0444,
         0.0370, -0.0417, -0.0435,  0.0223,  0.0348, -0.0301, -0.0267,  0.0423,
         0.0560,  0.0440, -0.0356,  0.0378, -0.0181,  0.0381,  0.0455, -0.0374,
         0.0224, -0.0304, -0.0299,  0.0201,  0.0319,  0.0462],
       dtype=torch.float64, requires_grad=True)
Attempt 4: Optimization failed with error: list index out of range
w_i_init_torch: tensor([ 0.0446, -0.0301,  0.0305, -0.0374,  0.0388,  0.0362, -0.0501, -0.0419,
         0.0296,  0.0394,  0.0463, -0.0265, -0.0260,  0.0142, -0.0339,  0.0207,
        -0.0199,  0.0153,  0.0165, -0.0451,  0.0303,  0.0311,  0.0330,  0.0360,
         0.0502, -0.0371,  0.0445,  0.0319, -0.0550, -0.0211],
       dtype=torch.float64, requires_grad=True)
Attempt 5: Optimization failed with error: list index out of range
w_i_init_torch: tensor([ 0.0230, -0.0265, -0.0383, -0.0293,  0.0337, -0.0375, -0.0388,  0.0332,
         0.0498,  0.0399,  0.0322, -0.0219,  0.0233, -0.0419, -0.0337, -0.0319,
         0.0211,  0.0354,  0.0441,  0.0382, -0.0283,  0.0283, -0.0289, -0.0347,
        -0.0154, -0.0524, -0.0328,  0.0242, -0.0306,  0.0268],
       dtype=torch.float64, requires_grad=True)
Attempt 6: Optimization failed with error: list index out of range
w_i_init_torch: tensor([-0.0336, -0.0273,  0.0487,  0.0460, -0.0316, -0.0275,  0.0376, -0.0341,
        -0.0402,  0.0071,  0.0398,  0.0264,  0.0283, -0.0236,  0.0515,  0.0195,
        -0.0241, -0.0251, -0.0402, -0.0421, -0.0374, -0.0215,  0.0199, -0.0336,
         0.0071, -0.0418,  0.0243,  0.0283,  0.0249,  0.0303],
       dtype=torch.float64, requires_grad=True)
Attempt 7: Optimization failed with error: list index out of range
w_i_init_torch: tensor([-0.0427, -0.0290, -0.0101, -0.0452, -0.0457, -0.0437,  0.0218, -0.0292,
        -0.0310, -0.0350, -0.0313,  0.0255, -0.0056,  0.0400,  0.0318, -0.0362,
         0.0473,  0.0258,  0.0377, -0.0549, -0.0309, -0.0178, -0.0283, -0.0456,
        -0.0250,  0.0217, -0.0186, -0.0491,  0.0376,  0.0198],
       dtype=torch.float64, requires_grad=True)
Attempt 8: Optimization failed with error: list index out of range
w_i_init_torch: tensor([ 0.0370, -0.0253,  0.0290, -0.0235, -0.0348, -0.0312, -0.0287,  0.0316,
         0.0356,  0.0386, -0.0360,  0.0356, -0.0301,  0.0397,  0.0219, -0.0474,
         0.0390, -0.0281,  0.0189,  0.0301, -0.0390, -0.0227, -0.0309,  0.0219,
         0.0451,  0.0382, -0.0334,  0.0284, -0.0491,  0.0362],
       dtype=torch.float64, requires_grad=True)
Attempt 9: Optimization failed with error: list index out of range
w_i_init_torch: tensor([ 0.0293,  0.0511,  0.0337,  0.0561,  0.0445,  0.0356, -0.0350, -0.0368,
        -0.0361,  0.0218,  0.0202, -0.0288, -0.0412,  0.0297,  0.0222, -0.0228,
         0.0171, -0.0424,  0.0092, -0.0372,  0.0393,  0.0378,  0.0328, -0.0159,
        -0.0382, -0.0317,  0.0307, -0.0316, -0.0224, -0.0097],
       dtype=torch.float64, requires_grad=True)
Attempt 10: Optimization failed with error: list index out of range
w_i_init_torch: tensor([-0.0292,  0.0194, -0.0185,  0.0367,  0.0388, -0.0522,  0.0354, -0.0650,
        -0.0324, -0.0383,  0.0244, -0.0184,  0.0396, -0.0418, -0.0354,  0.0258,
        -0.0494,  0.0402, -0.0337, -0.0310, -0.0503,  0.0122, -0.0444,  0.0256,
         0.0313, -0.0194,  0.0418, -0.0270, -0.0188, -0.0257],
       dtype=torch.float64, requires_grad=True)
Attempt 11: Optimization failed with error: list index out of range
w_i_init_torch: tensor([ 0.0549, -0.0281, -0.0348,  0.0271,  0.0463,  0.0395,  0.0155,  0.0307,
        -0.0392, -0.0370,  0.0442, -0.0309, -0.0247,  0.0427,  0.0247,  0.0525,
         0.0437,  0.0246,  0.0342,  0.0306, -0.0396,  0.0325, -0.0445, -0.0056,
        -0.0192, -0.0262, -0.0133, -0.0328,  0.0258, -0.0355],
       dtype=torch.float64, requires_grad=True)
Attempt 12: Optimization failed with error: list index out of range
w_i_init_torch: tensor([-0.0316, -0.0475,  0.0357,  0.0217,  0.0203, -0.0379,  0.0388, -0.0376,
        -0.0381, -0.0227,  0.0298,  0.0231, -0.0443, -0.0416,  0.0240, -0.0337,
        -0.0289,  0.0446,  0.0207, -0.0220,  0.0306,  0.0394, -0.0359, -0.0424,
        -0.0180, -0.0324,  0.0338,  0.0392, -0.0406, -0.0374],
       dtype=torch.float64, requires_grad=True)
Attempt 13: Optimization failed with error: list index out of range
w_i_init_torch: tensor([-0.0171,  0.0432, -0.0426,  0.0336,  0.0383,  0.0484,  0.0421, -0.0329,
         0.0362,  0.0225,  0.0204,  0.0369, -0.0436, -0.0506,  0.0181,  0.0253,
         0.0415, -0.0240, -0.0413,  0.0343,  0.0485,  0.0396,  0.0508, -0.0231,
         0.0212, -0.0491,  0.0363,  0.0336, -0.0284,  0.0269],
       dtype=torch.float64, requires_grad=True)
Final loss (NLL): 0.517570374556452
Final weights: tensor([-0.0409, -0.0420,  0.1275,  0.0114, -0.0392,  0.0973, -0.0519,  0.1822,
         0.0596,  0.1346,  0.1341,  0.0109,  0.0556, -0.1576, -0.0436, -0.0629,
         0.0243,  0.0806,  0.0929,  0.1870,  0.0309,  0.0915, -0.0046,  0.0696,
        -0.0817,  0.0895,  0.0855,  0.0563, -0.0736, -0.0231],
       dtype=torch.float64)
Sum of weights: 0.9999999477387135
Weight covariance matrix:
 tensor([[ 2.2790e-03, -9.5482e-05, -2.4467e-04, -3.0734e-04, -9.4359e-05,
         -2.7693e-04,  2.6387e-04, -1.8583e-04, -2.7934e-04, -1.6963e-05,
         -1.2785e-04, -2.3037e-04,  1.4046e-04,  3.7161e-05, -4.2097e-06,
         -4.7119e-05, -2.1134e-04, -2.4476e-04, -2.1979e-04, -1.8613e-04,
          1.3815e-05, -3.8803e-04, -4.9766e-05, -4.5295e-05,  1.2488e-04,
          2.8766e-04,  2.2131e-05, -6.9485e-05,  9.0975e-05,  6.5142e-05],
        [-9.5482e-05,  1.4742e-03, -3.4061e-04,  5.8650e-05, -1.7950e-04,
         -2.0371e-04, -1.4407e-04,  1.2877e-04,  8.9711e-05, -1.9161e-04,
          6.5022e-05,  1.1894e-04,  8.8530e-05,  4.8053e-05, -2.3639e-05,
          1.3365e-04,  1.5337e-04, -2.6086e-05, -1.4917e-04, -3.5267e-04,
         -2.7825e-04, -1.1568e-05, -4.9779e-05,  2.8413e-05, -1.5422e-04,
         -2.1065e-04, -2.5180e-04,  1.9683e-04,  1.1316e-04, -3.4527e-05],
        [-2.4467e-04, -3.4061e-04,  2.5158e-03,  1.2218e-04, -1.0943e-04,
         -6.0820e-05, -1.4639e-04,  2.4741e-05, -4.5917e-04,  2.5246e-04,
         -2.1029e-04, -1.2934e-04, -1.4216e-04,  2.8444e-04, -1.9692e-04,
         -1.0473e-04, -1.2848e-04, -2.9610e-04,  1.9494e-04, -4.5715e-06,
         -1.6335e-04, -3.0291e-04,  5.6694e-05, -1.4426e-04, -7.5952e-05,
         -6.3088e-05,  7.7814e-05, -3.7449e-05,  7.8217e-05, -2.4655e-04],
        [-3.0734e-04,  5.8650e-05,  1.2218e-04,  1.2831e-03, -4.3492e-05,
          2.7705e-05, -1.8782e-04,  1.5326e-04, -1.8398e-04,  3.0607e-05,
         -2.1797e-05,  4.5921e-05, -1.4777e-04,  2.0303e-05, -1.1124e-06,
         -9.6061e-05,  8.0217e-05, -1.2528e-04, -4.1904e-05, -5.1463e-05,
         -2.8628e-05, -1.5116e-05, -2.8024e-05, -1.8091e-04,  3.4410e-06,
         -2.1742e-04, -2.7457e-05, -6.4248e-05,  7.0741e-05, -1.2625e-04],
        [-9.4359e-05, -1.7950e-04, -1.0943e-04, -4.3492e-05,  1.3920e-03,
          9.5687e-06, -1.0117e-04,  2.0345e-04,  6.0902e-05,  2.1645e-04,
         -5.6533e-05, -1.0139e-04, -8.9982e-06, -6.3690e-04, -5.7262e-05,
         -3.5592e-05, -1.3644e-04,  8.9908e-05, -1.4071e-04, -5.3506e-04,
          2.4023e-04,  1.9436e-04, -2.2740e-04,  1.3736e-04, -2.3115e-04,
          8.8529e-05, -2.8519e-05,  7.3763e-05, -1.0756e-04,  1.2497e-04],
        [-2.7693e-04, -2.0371e-04, -6.0820e-05,  2.7705e-05,  9.5687e-06,
          2.4861e-03, -1.6289e-04, -1.7888e-04, -2.1726e-04, -1.6513e-06,
         -1.8467e-04,  6.1378e-05, -1.1292e-04, -1.8036e-04,  1.4985e-04,
         -1.4110e-04,  1.7457e-04,  4.6675e-05,  1.8666e-04, -5.8327e-05,
          8.3812e-05, -2.4964e-04,  1.1402e-04,  4.9655e-05, -8.7467e-05,
         -1.8276e-04, -3.9684e-04, -1.6611e-04, -2.2837e-04, -2.9927e-04],
        [ 2.6387e-04, -1.4407e-04, -1.4639e-04, -1.8782e-04, -1.0117e-04,
         -1.6289e-04,  1.9078e-03, -4.4728e-04, -1.2621e-04, -2.0680e-05,
          1.8946e-05, -1.1095e-04, -1.1625e-04, -2.7843e-04, -5.8731e-05,
         -3.0234e-05, -2.3173e-04,  1.2923e-04, -4.5151e-05, -1.7136e-04,
         -5.0131e-05, -3.2398e-04,  1.7753e-04, -2.7023e-04,  1.2388e-04,
          2.6343e-04,  1.8467e-04,  1.2964e-04, -3.8969e-05, -1.3632e-04],
        [-1.8583e-04,  1.2877e-04,  2.4741e-05,  1.5326e-04,  2.0345e-04,
         -1.7888e-04, -4.4728e-04,  2.4437e-03,  1.9636e-04, -3.2596e-04,
          1.9650e-04, -3.7331e-05, -1.0160e-04, -1.6466e-04, -6.5105e-05,
         -2.5314e-04, -3.4488e-04, -1.4456e-04, -1.7475e-04,  1.3094e-04,
         -2.8022e-05, -5.9951e-05, -1.3589e-04, -4.1480e-06, -7.2196e-05,
         -2.9993e-04, -6.6712e-05, -9.8102e-05, -5.0384e-05, -2.3842e-04],
        [-2.7934e-04,  8.9711e-05, -4.5917e-04, -1.8398e-04,  6.0902e-05,
         -2.1726e-04, -1.2621e-04,  1.9636e-04,  2.8028e-03, -3.1384e-04,
         -5.7132e-05,  1.8279e-04,  3.9918e-05,  3.3646e-05,  1.3181e-04,
          2.4070e-05, -3.5905e-04, -1.5029e-04, -1.3723e-04, -4.7353e-05,
         -2.0720e-05,  3.5112e-04,  3.4692e-05, -1.0329e-04, -1.0526e-04,
         -4.0764e-04, -2.7969e-04, -3.0191e-04, -1.9683e-04, -2.0165e-04],
        [-1.6963e-05, -1.9161e-04,  2.5246e-04,  3.0607e-05,  2.1645e-04,
         -1.6513e-06, -2.0680e-05, -3.2596e-04, -3.1384e-04,  2.7036e-03,
         -3.6084e-05, -1.9149e-04, -5.5602e-05,  8.1180e-05, -5.9688e-05,
          1.6644e-04, -2.4437e-04, -4.2663e-04,  1.0424e-04, -3.8820e-04,
          2.1705e-04, -4.4578e-04, -4.6479e-05, -1.3482e-04, -1.3696e-04,
         -1.7720e-04, -1.2667e-04, -1.5142e-04, -2.5495e-04, -2.4968e-05],
        [-1.2785e-04,  6.5022e-05, -2.1029e-04, -2.1797e-05, -5.6533e-05,
         -1.8467e-04,  1.8946e-05,  1.9650e-04, -5.7132e-05, -3.6084e-05,
          2.0131e-03, -4.8262e-05, -1.9073e-05,  5.7857e-05, -2.2720e-05,
         -2.3222e-05, -3.6250e-04, -8.4991e-05, -1.3182e-04,  9.6606e-06,
         -1.4924e-04, -1.7085e-05, -1.0406e-04, -2.0266e-04,  1.7659e-04,
         -2.4032e-04, -7.8420e-05, -7.1321e-05, -8.6165e-05, -2.0150e-04],
        [-2.3037e-04,  1.1894e-04, -1.2934e-04,  4.5921e-05, -1.0139e-04,
          6.1378e-05, -1.1095e-04, -3.7331e-05,  1.8279e-04, -1.9149e-04,
         -4.8262e-05,  1.6044e-03, -1.4692e-05, -3.0229e-05,  8.5960e-05,
          1.4227e-04,  3.4037e-05,  7.4395e-06, -2.4067e-04, -1.5186e-04,
          2.8964e-05, -1.7386e-04,  4.8675e-06, -5.3950e-05,  1.2383e-05,
         -2.2328e-04, -2.6593e-04,  1.3908e-05, -2.3480e-04, -1.0487e-04],
        [ 1.4046e-04,  8.8530e-05, -1.4216e-04, -1.4777e-04, -8.9982e-06,
         -1.1292e-04, -1.1625e-04, -1.0160e-04,  3.9918e-05, -5.5602e-05,
         -1.9073e-05, -1.4692e-05,  2.0431e-03, -2.3686e-04,  9.4669e-06,
         -1.9932e-04,  6.9138e-05, -2.2552e-06, -3.6657e-04, -3.7598e-04,
         -6.2621e-04, -3.0754e-04, -5.2449e-05, -7.9760e-06,  2.4911e-04,
          1.1403e-04, -4.0250e-05,  2.4112e-05,  3.7417e-05,  1.1923e-04],
        [ 3.7161e-05,  4.8053e-05,  2.8444e-04,  2.0303e-05, -6.3690e-04,
         -1.8036e-04, -2.7843e-04, -1.6466e-04,  3.3646e-05,  8.1180e-05,
          5.7857e-05, -3.0229e-05, -2.3686e-04,  2.7235e-03,  2.2999e-05,
         -2.2382e-05,  1.2342e-04, -7.5052e-04,  1.1879e-04,  4.4856e-04,
          1.6090e-05, -2.4673e-04, -4.4162e-04, -4.1265e-04, -8.5268e-05,
         -2.9659e-04, -4.1723e-04, -1.2995e-04,  2.9553e-04,  1.8828e-05],
        [-4.2097e-06, -2.3639e-05, -1.9692e-04, -1.1124e-06, -5.7262e-05,
          1.4985e-04, -5.8731e-05, -6.5105e-05,  1.3181e-04, -5.9688e-05,
         -2.2720e-05,  8.5960e-05,  9.4669e-06,  2.2999e-05,  7.3919e-04,
          9.3768e-05,  2.5264e-06, -6.0276e-05, -1.7473e-04, -7.1850e-05,
          1.3625e-05,  9.6307e-05, -1.6095e-05,  4.5372e-05,  7.4928e-05,
         -1.4154e-04, -2.2833e-04, -3.2247e-04,  3.8861e-05,  1.7902e-08],
        [-4.7119e-05,  1.3365e-04, -1.0473e-04, -9.6061e-05, -3.5592e-05,
         -1.4110e-04, -3.0234e-05, -2.5314e-04,  2.4070e-05,  1.6644e-04,
         -2.3222e-05,  1.4227e-04, -1.9932e-04, -2.2382e-05,  9.3768e-05,
          1.1475e-03, -2.1232e-04,  6.7094e-05, -1.3167e-04, -1.8232e-04,
          5.8555e-05,  1.0602e-04, -1.5000e-05,  7.6908e-05, -2.8044e-04,
         -3.8311e-05, -2.5928e-04, -6.1893e-05,  1.2433e-05,  1.0543e-04],
        [-2.1134e-04,  1.5337e-04, -1.2848e-04,  8.0217e-05, -1.3644e-04,
          1.7457e-04, -2.3173e-04, -3.4488e-04, -3.5905e-04, -2.4437e-04,
         -3.6250e-04,  3.4037e-05,  6.9138e-05,  1.2342e-04,  2.5264e-06,
         -2.1232e-04,  2.4200e-03,  1.1003e-04, -5.0108e-05, -1.8041e-04,
         -5.5357e-05, -9.7335e-05,  1.6970e-04,  1.9055e-04,  9.9095e-05,
         -1.6762e-04, -2.7831e-04,  1.3262e-04, -2.9929e-04, -3.9975e-04],
        [-2.4476e-04, -2.6086e-05, -2.9610e-04, -1.2528e-04,  8.9908e-05,
          4.6675e-05,  1.2923e-04, -1.4456e-04, -1.5029e-04, -4.2663e-04,
         -8.4991e-05,  7.4395e-06, -2.2552e-06, -7.5052e-04, -6.0276e-05,
          6.7094e-05,  1.1003e-04,  2.4497e-03, -2.0650e-04, -4.2254e-05,
         -2.1407e-04, -1.8227e-05,  1.5615e-04,  1.1069e-04,  1.0924e-04,
          7.9886e-06, -1.5632e-04, -4.4811e-05,  2.9271e-05, -3.1944e-04],
        [-2.1979e-04, -1.4917e-04,  1.9494e-04, -4.1904e-05, -1.4071e-04,
          1.8666e-04, -4.5151e-05, -1.7475e-04, -1.3723e-04,  1.0424e-04,
         -1.3182e-04, -2.4067e-04, -3.6657e-04,  1.1879e-04, -1.7473e-04,
         -1.3167e-04, -5.0108e-05, -2.0650e-04,  2.1617e-03,  1.8636e-04,
          1.2387e-05, -7.2176e-05,  1.3262e-04, -1.7998e-04, -4.8382e-05,
         -2.8613e-05, -3.9624e-05, -1.3835e-04, -1.8066e-05, -3.6172e-04],
        [-1.8613e-04, -3.5267e-04, -4.5715e-06, -5.1463e-05, -5.3506e-04,
         -5.8327e-05, -1.7136e-04,  1.3094e-04, -4.7353e-05, -3.8820e-04,
          9.6606e-06, -1.5186e-04, -3.7598e-04,  4.4856e-04, -7.1850e-05,
         -1.8232e-04, -1.8041e-04, -4.2254e-05,  1.8636e-04,  2.6281e-03,
          7.7852e-05, -2.0344e-04,  2.1884e-05, -4.3274e-05, -2.4448e-04,
         -7.3262e-05,  1.2441e-04, -1.8474e-04,  1.2335e-04, -2.0214e-04],
        [ 1.3815e-05, -2.7825e-04, -1.6335e-04, -2.8628e-05,  2.4023e-04,
          8.3812e-05, -5.0131e-05, -2.8022e-05, -2.0720e-05,  2.1705e-04,
         -1.4924e-04,  2.8964e-05, -6.2621e-04,  1.6090e-05,  1.3625e-05,
          5.8555e-05, -5.5357e-05, -2.1407e-04,  1.2387e-05,  7.7852e-05,
          1.6856e-03,  1.4659e-04, -1.0444e-04,  3.1282e-05, -3.8532e-04,
         -1.9402e-04, -5.7657e-05, -5.6369e-05, -3.8469e-04,  1.7059e-04],
        [-3.8803e-04, -1.1568e-05, -3.0291e-04, -1.5116e-05,  1.9436e-04,
         -2.4964e-04, -3.2398e-04, -5.9951e-05,  3.5112e-04, -4.4578e-04,
         -1.7085e-05, -1.7386e-04, -3.0754e-04, -2.4673e-04,  9.6307e-05,
          1.0602e-04, -9.7335e-05, -1.8227e-05, -7.2176e-05, -2.0344e-04,
          1.4659e-04,  2.4151e-03,  1.1032e-04, -4.2029e-05,  9.3376e-05,
         -2.1272e-04, -8.3902e-06, -3.5204e-04, -8.5796e-05,  1.2113e-04],
        [-4.9766e-05, -4.9779e-05,  5.6694e-05, -2.8024e-05, -2.2740e-04,
          1.1402e-04,  1.7753e-04, -1.3589e-04,  3.4692e-05, -4.6479e-05,
         -1.0406e-04,  4.8675e-06, -5.2449e-05, -4.4162e-04, -1.6095e-05,
         -1.5000e-05,  1.6970e-04,  1.5615e-04,  1.3262e-04,  2.1884e-05,
         -1.0444e-04,  1.1032e-04,  5.3639e-04, -1.3100e-04,  8.0474e-05,
         -1.6709e-05,  1.0863e-04,  4.6970e-05, -1.4863e-04, -1.8360e-04],
        [-4.5295e-05,  2.8413e-05, -1.4426e-04, -1.8091e-04,  1.3736e-04,
          4.9655e-05, -2.7023e-04, -4.1480e-06, -1.0329e-04, -1.3482e-04,
         -2.0266e-04, -5.3950e-05, -7.9760e-06, -4.1265e-04,  4.5372e-05,
          7.6908e-05,  1.9055e-04,  1.1069e-04, -1.7998e-04, -4.3274e-05,
          3.1282e-05, -4.2029e-05, -1.3100e-04,  1.9252e-03, -2.0253e-04,
         -1.0975e-04, -1.4662e-04, -1.3341e-05, -1.6799e-04,  1.2522e-06],
        [ 1.2488e-04, -1.5422e-04, -7.5952e-05,  3.4410e-06, -2.3115e-04,
         -8.7467e-05,  1.2388e-04, -7.2196e-05, -1.0526e-04, -1.3696e-04,
          1.7659e-04,  1.2383e-05,  2.4911e-04, -8.5268e-05,  7.4928e-05,
         -2.8044e-04,  9.9095e-05,  1.0924e-04, -4.8382e-05, -2.4448e-04,
         -3.8532e-04,  9.3376e-05,  8.0474e-05, -2.0253e-04,  9.4682e-04,
          5.2194e-05, -6.4533e-05,  3.1567e-05, -1.4630e-05,  1.0801e-05],
        [ 2.8766e-04, -2.1065e-04, -6.3088e-05, -2.1742e-04,  8.8529e-05,
         -1.8276e-04,  2.6343e-04, -2.9993e-04, -4.0764e-04, -1.7720e-04,
         -2.4032e-04, -2.2328e-04,  1.1403e-04, -2.9659e-04, -1.4154e-04,
         -3.8311e-05, -1.6762e-04,  7.9886e-06, -2.8613e-05, -7.3262e-05,
         -1.9402e-04, -2.1272e-04, -1.6709e-05, -1.0975e-04,  5.2194e-05,
          2.1569e-03,  1.3743e-04,  2.0591e-04,  5.9808e-05, -7.2457e-05],
        [ 2.2131e-05, -2.5180e-04,  7.7814e-05, -2.7457e-05, -2.8519e-05,
         -3.9684e-04,  1.8467e-04, -6.6712e-05, -2.7969e-04, -1.2667e-04,
         -7.8420e-05, -2.6593e-04, -4.0250e-05, -4.1723e-04, -2.2833e-04,
         -2.5928e-04, -2.7831e-04, -1.5632e-04, -3.9624e-05,  1.2441e-04,
         -5.7657e-05, -8.3902e-06,  1.0863e-04, -1.4662e-04, -6.4533e-05,
          1.3743e-04,  2.4739e-03,  8.4683e-05, -9.0707e-05,  9.5587e-05],
        [-6.9485e-05,  1.9683e-04, -3.7449e-05, -6.4248e-05,  7.3763e-05,
         -1.6611e-04,  1.2964e-04, -9.8102e-05, -3.0191e-04, -1.5142e-04,
         -7.1321e-05,  1.3908e-05,  2.4112e-05, -1.2995e-04, -3.2247e-04,
         -6.1893e-05,  1.3262e-04, -4.4811e-05, -1.3835e-04, -1.8474e-04,
         -5.6369e-05, -3.5204e-04,  4.6970e-05, -1.3341e-05,  3.1567e-05,
          2.0591e-04,  8.4683e-05,  1.7052e-03, -3.5979e-04, -2.1408e-05],
        [ 9.0975e-05,  1.1316e-04,  7.8217e-05,  7.0741e-05, -1.0756e-04,
         -2.2837e-04, -3.8969e-05, -5.0384e-05, -1.9683e-04, -2.5495e-04,
         -8.6165e-05, -2.3480e-04,  3.7417e-05,  2.9553e-04,  3.8861e-05,
          1.2433e-05, -2.9929e-04,  2.9271e-05, -1.8066e-05,  1.2335e-04,
         -3.8469e-04, -8.5796e-05, -1.4863e-04, -1.6799e-04, -1.4630e-05,
          5.9808e-05, -9.0707e-05, -3.5979e-04,  1.8341e-03, -1.6275e-05],
        [ 6.5142e-05, -3.4527e-05, -2.4655e-04, -1.2625e-04,  1.2497e-04,
         -2.9927e-04, -1.3632e-04, -2.3842e-04, -2.0165e-04, -2.4968e-05,
         -2.0150e-04, -1.0487e-04,  1.1923e-04,  1.8828e-05,  1.7902e-08,
          1.0543e-04, -3.9975e-04, -3.1944e-04, -3.6172e-04, -2.0214e-04,
          1.7059e-04,  1.2113e-04, -1.8360e-04,  1.2522e-06,  1.0801e-05,
         -7.2457e-05,  9.5587e-05, -2.1408e-05, -1.6275e-05,  2.3581e-03]],
       dtype=torch.float64, grad_fn=<DivBackward0>)
Skipping w_7 due to NaN or Inf in NLL values.
Skipping w_10 due to NaN or Inf in NLL values.
Skipping w_19 due to NaN or Inf in NLL values.
Skipping w_26 due to NaN or Inf in NLL values.
