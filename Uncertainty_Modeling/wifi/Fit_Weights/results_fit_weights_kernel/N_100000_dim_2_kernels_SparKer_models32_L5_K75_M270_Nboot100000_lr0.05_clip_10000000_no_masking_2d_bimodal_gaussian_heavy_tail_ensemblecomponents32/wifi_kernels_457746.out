Using folder_path = /work/gbadarac/MonoJet_NPLM/MonoJet_NPLM_analysis/Train_Ensembles/Train_Models/Sparker_kernels/EstimationKernels_outputs/2_dim/2d_bimodal_gaussian_heavy_tail/N_100000_dim_2_kernels_SparKer_models32_L5_K75_M270_Nboot100000_lr0.05_clip_10000000_no_masking
Storing WiFi fit results in: /work/gbadarac/MonoJet_NPLM/MonoJet_NPLM_analysis/Uncertainty_Modeling/wifi/Fit_Weights/results_fit_weights_kernel/N_100000_dim_2_kernels_SparKer_models32_L5_K75_M270_Nboot100000_lr0.05_clip_10000000_no_masking_2d_bimodal_gaussian_heavy_tail_ensemblecomponents32_new_plotting
Loaded target data: (100000, 2)
Precomputing model_probs on CPU ...
model_probs stats: min 3.6376149562588196e-12 max 1.8383188729183293 finite True
model_probs_cpu computed: shape=(100000, 32)
w_init: [0.02873597 0.03709793 0.04688101 0.01359625 0.02969638 0.0262363
 0.04561542 0.02722097 0.02842287 0.02964455 0.01432479 0.02754294
 0.03842044 0.00744456 0.02253563 0.01807215 0.02677364 0.02389244
 0.03290042 0.01120366 0.01906616 0.02617355 0.00864003 0.03654217
 0.04836858 0.01836386 0.0467666  0.04809792 0.02248883 0.04588594
 0.03886163 0.04944305]
w_init sum: 0.9449566258699263
epoch 100 loss 3.964658e-01 |dL/du| 1.640e-05
epoch 100 sumw 1.000000
epoch 100 weights [ 0.06358105  0.06494789  0.02018986  0.03932356 -0.03928792 -0.05915908
  0.06684981  0.06314139  0.09429362  0.05905452 -0.00439005  0.01428611
  0.03541742  0.03594871 -0.01209058  0.03234332  0.10016187 -0.00909434
  0.10908661 -0.08715175  0.01104064  0.02461422  0.00497289 -0.00109058
  0.04595776  0.02502496  0.08273952 -0.06158151  0.11755565  0.02560011
  0.03682494  0.10088938]
epoch 200 loss 3.964658e-01 |dL/du| 9.702e-08
epoch 200 sumw 1.000000
epoch 200 weights [ 0.06355559  0.06476207  0.02045626  0.03936551 -0.03922247 -0.05892636
  0.06688139  0.06284522  0.09421682  0.0590383  -0.0042803   0.01424256
  0.03541078  0.03606192 -0.01190138  0.03227795  0.1004362  -0.0089022
  0.10895922 -0.08688681  0.01125912  0.02431154  0.00485848 -0.00104033
  0.04580927  0.02498787  0.08264295 -0.06172869  0.11728518  0.02551144
  0.03675498  0.10095791]
epoch 300 loss 3.964658e-01 |dL/du| 7.144e-10
epoch 300 sumw 1.000000
epoch 300 weights [ 0.06355619  0.0647632   0.02045478  0.03936543 -0.03922362 -0.05892756
  0.06688128  0.06284662  0.09421674  0.05903893 -0.0042802   0.01424303
  0.03540928  0.03606059 -0.01190207  0.03227854  0.10043602 -0.00890197
  0.10896182 -0.08688795  0.01125938  0.02431178  0.00485835 -0.00104041
  0.04580947  0.02498817  0.08264184 -0.06173002  0.1172865   0.02551347
  0.0367549   0.1009575 ]
epoch 400 loss 3.964658e-01 |dL/du| 4.886e-07
epoch 400 sumw 1.000000
epoch 400 weights [ 0.06355696  0.06476381  0.02045544  0.03936593 -0.03922317 -0.0589273
  0.06688199  0.06284738  0.09421734  0.0590397  -0.00427949  0.01424359
  0.03541     0.03606133 -0.01190145  0.03227926  0.10043669 -0.00890129
  0.10896231 -0.08688742  0.01126008  0.02431243  0.00485903 -0.00103995
  0.04581024  0.02498888  0.0826425  -0.0617295   0.11728704  0.02551406
  0.03675567  0.10093788]
epoch 500 loss 3.964658e-01 |dL/du| 9.486e-06
epoch 500 sumw 1.000000
epoch 500 weights [ 0.06353104  0.0647432   0.02043301  0.03934779 -0.03924468 -0.05894107
  0.06686189  0.06282327  0.09419281  0.05901387 -0.0043069   0.0142202
  0.03538409  0.0360364  -0.01192178  0.03225632  0.10041233 -0.00892817
  0.10894153 -0.08690853  0.01123666  0.02428854  0.00483377 -0.00106008
  0.04578403  0.0249642   0.0826189  -0.06175135  0.1172653   0.02549206
  0.03673062  0.10165077]
epoch 600 loss 3.964658e-01 |dL/du| 9.568e-08
epoch 600 sumw 1.000000
epoch 600 weights [ 0.063556    0.06476302  0.02045459  0.03936526 -0.03922377 -0.05892766
  0.06688111  0.06284646  0.09421656  0.05903875 -0.00428039  0.01424288
  0.0354091   0.0360604  -0.01190227  0.03227834  0.10043583 -0.00890214
  0.10896166 -0.08688813  0.01125919  0.02431163  0.00485817 -0.00104054
  0.04580928  0.02498798  0.08264164 -0.06173018  0.11728632  0.02551331
  0.03675472  0.10096288]
epoch 700 loss 3.964658e-01 |dL/du| 7.836e-10
epoch 700 sumw 1.000000
epoch 700 weights [ 0.06355619  0.0647632   0.02045477  0.03936542 -0.03922362 -0.05892756
  0.06688128  0.06284664  0.09421674  0.05903894 -0.0042802   0.01424303
  0.03540927  0.03606059 -0.01190208  0.03227854  0.10043602 -0.00890197
  0.10896182 -0.08688796  0.01125938  0.02431179  0.00485835 -0.00104041
  0.04580947  0.02498817  0.08264183 -0.06173001  0.1172865   0.02551347
  0.0367549   0.10095752]
epoch 800 loss 3.964658e-01 |dL/du| 9.281e-11
epoch 800 sumw 1.000000
epoch 800 weights [ 0.06355619  0.0647632   0.02045477  0.03936542 -0.03922362 -0.05892756
  0.06688128  0.06284664  0.09421674  0.05903894 -0.0042802   0.01424303
  0.03540927  0.03606059 -0.01190208  0.03227854  0.10043602 -0.00890196
  0.10896182 -0.08688796  0.01125938  0.02431179  0.00485835 -0.00104041
  0.04580947  0.02498817  0.08264183 -0.06173001  0.1172865   0.02551347
  0.0367549   0.10095748]
epoch 900 loss 3.964659e-01 |dL/du| 5.093e-05
epoch 900 sumw 1.000000
epoch 900 weights [ 0.06365874  0.06485362  0.0205501   0.03945005 -0.03912771 -0.05887411
  0.06694746  0.06294253  0.0943174   0.05914506 -0.00417952  0.01432391
  0.03552225  0.03615885 -0.01181702  0.03236626  0.10052926 -0.0088037
  0.10905054 -0.08679032  0.01136002  0.02439347  0.00496053 -0.00095494
  0.04591679  0.0250887   0.08271285 -0.06165089  0.11738346  0.02560765
  0.03686493  0.09809377]
epoch 1000 loss 3.964658e-01 |dL/du| 7.740e-07
epoch 1000 sumw 1.000000
epoch 1000 weights [ 0.06355628  0.06476327  0.02045471  0.03936541 -0.03922364 -0.0589276
  0.06688118  0.06284669  0.09421675  0.05903897 -0.00428021  0.01424302
  0.0354094   0.03606061 -0.01190205  0.03227859  0.10043605 -0.00890191
  0.10896189 -0.08688791  0.01125944  0.02431178  0.00485837 -0.00104035
  0.04580951  0.02498816  0.08264191 -0.06173003  0.1172865   0.02551349
  0.03675496  0.10095675]
epoch 1100 loss 3.964658e-01 |dL/du| 5.235e-09
epoch 1100 sumw 1.000000
epoch 1100 weights [ 0.06355619  0.0647632   0.02045477  0.03936542 -0.03922362 -0.05892756
  0.06688128  0.06284664  0.09421674  0.05903894 -0.0042802   0.01424303
  0.03540927  0.03606059 -0.01190208  0.03227854  0.10043602 -0.00890197
  0.10896182 -0.08688796  0.01125938  0.02431179  0.00485835 -0.00104041
  0.04580947  0.02498817  0.08264183 -0.06173001  0.1172865   0.02551347
  0.0367549   0.10095754]
epoch 1200 loss 3.964658e-01 |dL/du| 3.039e-11
epoch 1200 sumw 1.000000
epoch 1200 weights [ 0.06355619  0.0647632   0.02045477  0.03936542 -0.03922362 -0.05892756
  0.06688128  0.06284664  0.09421674  0.05903894 -0.0042802   0.01424303
  0.03540927  0.03606059 -0.01190208  0.03227854  0.10043602 -0.00890196
  0.10896182 -0.08688796  0.01125938  0.02431179  0.00485835 -0.00104041
  0.04580947  0.02498817  0.08264183 -0.06173001  0.1172865   0.02551347
  0.0367549   0.10095749]
epoch 1300 loss 3.964658e-01 |dL/du| 6.688e-06
epoch 1300 sumw 1.000000
epoch 1300 weights [ 0.06354767  0.06475493  0.02044643  0.03935745 -0.03923132 -0.05893385
  0.06687285  0.06283819  0.09420855  0.05903045 -0.00428859  0.01423487
  0.03540086  0.03605212 -0.01191037  0.03227012  0.10042765 -0.0089103
  0.10895402 -0.08689595  0.011251    0.02430347  0.00484999 -0.00104818
  0.04580097  0.02497973  0.08263347 -0.06173794  0.1172785   0.02550531
  0.0367464   0.1012115 ]
epoch 1400 loss 3.964658e-01 |dL/du| 1.917e-05
epoch 1400 sumw 1.000000
epoch 1400 weights [ 0.06356251  0.06476971  0.02046556  0.03937404 -0.03921683 -0.0589161
  0.06689276  0.06285688  0.0942207   0.0590469  -0.00427136  0.01425545
  0.03541532  0.03606956 -0.0118938   0.03228234  0.10044193 -0.00889225
  0.10896575 -0.08688096  0.01126654  0.02432279  0.0048641  -0.00102985
  0.04581867  0.02499445  0.08264854 -0.06172182  0.11729455  0.02551956
  0.03676295  0.10071138]
epoch 1500 loss 3.964658e-01 |dL/du| 2.508e-08
epoch 1500 sumw 1.000000
epoch 1500 weights [ 0.06355632  0.06476332  0.02045488  0.03936552 -0.03922351 -0.05892747
  0.06688139  0.06284675  0.09421688  0.05903906 -0.00428006  0.01424313
  0.03540939  0.03606071 -0.01190195  0.03227869  0.10043615 -0.00890183
  0.10896194 -0.08688784  0.01125951  0.02431189  0.00485847 -0.0010403
  0.0458096   0.02498829  0.08264196 -0.06172989  0.11728663  0.02551358
  0.03675502  0.10095378]
epoch 1600 loss 3.964658e-01 |dL/du| 1.118e-10
epoch 1600 sumw 1.000000
epoch 1600 weights [ 0.06355619  0.0647632   0.02045477  0.03936542 -0.03922362 -0.05892756
  0.06688128  0.06284664  0.09421674  0.05903894 -0.0042802   0.01424303
  0.03540927  0.03606059 -0.01190208  0.03227854  0.10043602 -0.00890196
  0.10896182 -0.08688796  0.01125938  0.02431179  0.00485835 -0.00104041
  0.04580947  0.02498817  0.08264183 -0.06173001  0.1172865   0.02551347
  0.0367549   0.1009575 ]
epoch 1700 loss 3.964658e-01 |dL/du| 8.283e-12
epoch 1700 sumw 1.000000
epoch 1700 weights [ 0.06355619  0.0647632   0.02045477  0.03936542 -0.03922362 -0.05892756
  0.06688128  0.06284664  0.09421674  0.05903894 -0.0042802   0.01424303
  0.03540927  0.03606059 -0.01190208  0.03227854  0.10043602 -0.00890196
  0.10896182 -0.08688796  0.01125938  0.02431179  0.00485835 -0.00104041
  0.04580947  0.02498817  0.08264183 -0.06173001  0.1172865   0.02551347
  0.0367549   0.10095749]
epoch 1800 loss 3.964658e-01 |dL/du| 1.648e-05
epoch 1800 sumw 1.000000
epoch 1800 weights [ 0.06357637  0.06478313  0.02047473  0.03938497 -0.03920444 -0.05891045
  0.06690138  0.06286673  0.09423652  0.05905908 -0.0042602   0.01426283
  0.03542932  0.03608069 -0.01188216  0.03229861  0.10045602 -0.00888202
  0.10898109 -0.08686844  0.0112794   0.02433178  0.00487832 -0.00102111
  0.04582963  0.02500825  0.08266181 -0.06171057  0.11730604  0.02553321
  0.03677506  0.10034442]
epoch 1900 loss 3.964658e-01 |dL/du| 2.795e-05
epoch 1900 sumw 1.000000
epoch 1900 weights [ 0.06355042  0.06475385  0.0204491   0.03935441 -0.03922693 -0.05893702
  0.06687472  0.06284063  0.0942114   0.05903219 -0.00428574  0.01423473
  0.03540043  0.03605569 -0.01190931  0.03227007  0.10043038 -0.00890662
  0.10895667 -0.08689433  0.01125293  0.02430398  0.00485351 -0.00104799
  0.04580343  0.0249816   0.08263613 -0.06173459  0.11728111  0.02550589
  0.03674913  0.10116014]
epoch 2000 loss 3.964658e-01 |dL/du| 6.340e-08
epoch 2000 sumw 1.000000
epoch 2000 weights [ 0.06355631  0.06476332  0.02045491  0.03936556 -0.0392235  -0.05892742
  0.06688143  0.06284677  0.09421686  0.05903906 -0.00428009  0.01424317
  0.03540938  0.0360607  -0.01190195  0.03227867  0.10043614 -0.00890185
  0.10896193 -0.08688785  0.01125949  0.02431192  0.00485846 -0.00104028
  0.04580959  0.0249883   0.08264196 -0.06172989  0.11728662  0.02551358
  0.03675502  0.10095368]
Saved final_weights.npy and loss_history_wifi.npy
p_raw min/med/max: 7.503e-09 / 8.759e-01 / 1.695e+00
p     min/med/max: 6.931e-01 / 1.224e+00 / 1.864e+00
sum(w): 1.000000
L1(w):  1.545786e+00
max|w|: 1.172866e-01
fraction p_raw < 0: 0.0000
Hessian eigenvalues are [3.26322491e-03 3.52295217e-03 3.73569211e-03 4.04898509e-03
 4.51551066e-03 4.60172867e-03 5.01994795e-03 5.16294093e-03
 5.59088181e-03 5.81373619e-03 6.00143726e-03 6.35394191e-03
 6.56798028e-03 6.86757807e-03 7.07088903e-03 7.77685361e-03
 8.73478032e-03 8.93919397e-03 9.72361268e-03 1.02624914e-02
 1.05814426e-02 1.12624520e-02 1.29917877e-02 1.32044985e-02
 1.65171426e-02 1.85702077e-02 2.04627029e-02 2.22275942e-02
 2.94937978e-02 3.41460558e-02 5.24423867e-02 3.20207653e+01]
All done.
