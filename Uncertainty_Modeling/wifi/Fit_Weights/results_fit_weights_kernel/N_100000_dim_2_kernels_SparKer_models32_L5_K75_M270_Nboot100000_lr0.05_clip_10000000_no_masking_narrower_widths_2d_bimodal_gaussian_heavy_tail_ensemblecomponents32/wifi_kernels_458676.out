Using folder_path = /work/gbadarac/MonoJet_NPLM/MonoJet_NPLM_analysis/Train_Ensembles/Train_Models/Sparker_kernels/EstimationKernels_outputs/2_dim/2d_bimodal_gaussian_heavy_tail/N_100000_dim_2_kernels_SparKer_models32_L5_K75_M270_Nboot100000_lr0.05_clip_10000000_no_masking_narrower_widths
Storing WiFi fit results in: /work/gbadarac/MonoJet_NPLM/MonoJet_NPLM_analysis/Uncertainty_Modeling/wifi/Fit_Weights/results_fit_weights_kernel/N_100000_dim_2_kernels_SparKer_models32_L5_K75_M270_Nboot100000_lr0.05_clip_10000000_no_masking_narrower_widths_2d_bimodal_gaussian_heavy_tail_ensemblecomponents32
Loaded target data: (100000, 2)
Precomputing model_probs on CPU ...
model_probs stats: min 4.1288778721866644e-36 max 2.0028813697912793 finite True
model_probs_cpu computed: shape=(100000, 32)
w_init: [0.02602427 0.04658508 0.02645217 0.03684851 0.0484521  0.0237897
 0.03724597 0.02826178 0.0346284  0.01963625 0.01807644 0.02208013
 0.03199277 0.0284013  0.02185264 0.02403055 0.02917738 0.02564271
 0.02427821 0.03729049 0.03376679 0.03209313 0.03803019 0.05307232
 0.04111185 0.01855824 0.03613863 0.03748131 0.01501001 0.0418377
 0.04414039 0.02809007]
w_init sum: 1.0100774690553784
epoch 100 loss nan |dL/du| 3.473e-03
epoch 100 sumw 1.000000
epoch 100 weights [-0.06398865  0.09415035  0.0931566   0.0321311   0.0005403   0.04311977
  0.10962276  0.00313804  0.01446349  0.08075907  0.04301172  0.00241287
  0.0989718   0.0359331  -0.02115284  0.02024594  0.09266859 -0.01681871
  0.09582712 -0.05569955 -0.04972477  0.1341895   0.05747042  0.08500574
  0.06064386  0.03303541  0.04521808 -0.04358057  0.10385906  0.05084906
 -0.058253   -0.12120566]
epoch 200 loss nan |dL/du| 5.993e-04
epoch 200 sumw 1.000000
epoch 200 weights [-0.06814028  0.10961367  0.11389589  0.02750044 -0.02107918  0.04381132
  0.1182896  -0.00137955  0.01051345  0.10936004  0.04574061  0.00960651
  0.08658774  0.0362438  -0.01080308  0.02785968  0.11113634 -0.00464416
  0.11596909 -0.10567227 -0.07257772  0.11038803  0.07077456  0.09346889
  0.04582399  0.01898115  0.03848357 -0.03985369  0.10403648  0.06732489
 -0.06844789 -0.12281193]
epoch 300 loss nan |dL/du| 1.479e-04
epoch 300 sumw 1.000000
epoch 300 weights [-0.07062142  0.11454018  0.12163417  0.02301593 -0.02141065  0.04403074
  0.12421189 -0.00815748  0.00879488  0.11802916  0.04688619  0.00850906
  0.08829398  0.03063888 -0.01017363  0.02844488  0.1172555  -0.00472909
  0.12084175 -0.11497861 -0.07754689  0.10317027  0.07593379  0.09572722
  0.0431887   0.01789553  0.0350375  -0.03921656  0.10257237  0.06991563
 -0.06923915 -0.12249471]
epoch 400 loss nan |dL/du| 3.726e-05
epoch 400 sumw 1.000000
epoch 400 weights [-0.07137043  0.1162453   0.12355663  0.02215143 -0.02148649  0.04424152
  0.12578355 -0.01028372  0.00878973  0.12076927  0.04715085  0.00816086
  0.08931417  0.02706483 -0.01040112  0.02838269  0.11896137 -0.00508553
  0.12158792 -0.11681515 -0.07864185  0.10200635  0.07735211  0.09628166
  0.04336994  0.017749    0.03395528 -0.03887136  0.10199827  0.06986898
 -0.06948242 -0.12230366]
epoch 500 loss nan |dL/du| 8.708e-06
epoch 500 sumw 1.000000
epoch 500 weights [-0.07155522  0.11680276  0.1239884   0.02203495 -0.0215056   0.04431007
  0.12604833 -0.01072109  0.00883964  0.12158105  0.04718881  0.00812535
  0.08950216  0.02570086 -0.0105169   0.02834697  0.11929198 -0.00519072
  0.12169453 -0.11710915 -0.07885478  0.10195774  0.0776818   0.09646422
  0.04347073  0.01771716  0.03374057 -0.03879106  0.10179256  0.06974706
 -0.06954346 -0.12223974]
epoch 600 loss nan |dL/du| 1.735e-06
epoch 600 sumw 1.000000
epoch 600 weights [-0.0715945   0.11696239  0.12407089  0.02202035 -0.02150963  0.04433178
  0.12608274 -0.01079701  0.00885577  0.12177835  0.04719324  0.00812234
  0.08951427  0.02531847 -0.01055394  0.02833689  0.11933414 -0.00521106
  0.12171557 -0.11714458 -0.07889066  0.10197779  0.07774669  0.09652661
  0.04348704  0.01771025  0.03372046 -0.03878049  0.10173806  0.0697187
 -0.06955509 -0.12222583]
epoch 700 loss nan |dL/du| 2.828e-07
epoch 700 sumw 1.000000
epoch 700 weights [-0.07160147  0.11700029  0.12408318  0.02201809 -0.02151023  0.0443378
  0.12608626 -0.01080886  0.00885918  0.12181652  0.04719368  0.00812147
  0.08951171  0.02523543 -0.01056295  0.02833444  0.11933709 -0.00521415
  0.12172012 -0.11714789 -0.07889606  0.10198297  0.07775821  0.09654321
  0.04348842  0.01770887  0.03372245 -0.03877982  0.10172737  0.06971496
 -0.06955661 -0.12222369]
epoch 800 loss nan |dL/du| 3.666e-08
epoch 800 sumw 1.000000
epoch 800 weights [-0.07160248  0.11700743  0.12408456  0.02201771 -0.02151029  0.044339
  0.12608652 -0.01081046  0.00885972  0.12182239  0.04719371  0.00812121
  0.08951077  0.02522127 -0.01056458  0.02833395  0.11933707 -0.00521455
  0.12172093 -0.11714811 -0.07889677  0.10198367  0.07775999  0.09654648
  0.04348838  0.01770864  0.03372351 -0.03877988  0.10172575  0.06971466
 -0.06955674 -0.12222344]
epoch 900 loss nan |dL/du| 3.676e-09
epoch 900 sumw 1.000000
epoch 900 weights [-0.0716026   0.11700846  0.12408467  0.02201766 -0.02151029  0.04433917
  0.12608652 -0.01081063  0.00885979  0.1218231   0.04719371  0.00812116
  0.08951061  0.02521939 -0.0105648   0.02833387  0.11933704 -0.00521459
  0.12172105 -0.11714811 -0.07889685  0.10198374  0.07776022  0.09654696
  0.04348835  0.0177086   0.03372371 -0.03877991  0.10172555  0.06971465
 -0.06955674 -0.12222342]
epoch 1000 loss nan |dL/du| 2.761e-10
epoch 1000 sumw 1.000000
epoch 1000 weights [-0.07160261  0.11700857  0.12408468  0.02201765 -0.02151029  0.04433919
  0.12608652 -0.01081065  0.00885979  0.12182317  0.04719371  0.00812115
  0.0895106   0.02521919 -0.01056483  0.02833386  0.11933703 -0.00521459
  0.12172106 -0.11714811 -0.07889686  0.10198374  0.07776024  0.09654701
  0.04348834  0.0177086   0.03372373 -0.03877991  0.10172553  0.06971465
 -0.06955674 -0.12222342]
epoch 1100 loss nan |dL/du| 1.490e-11
epoch 1100 sumw 1.000000
epoch 1100 weights [-0.07160262  0.11700858  0.12408468  0.02201765 -0.02151029  0.04433919
  0.12608652 -0.01081065  0.00885979  0.12182317  0.04719371  0.00812115
  0.08951059  0.02521918 -0.01056483  0.02833386  0.11933703 -0.00521459
  0.12172106 -0.11714811 -0.07889686  0.10198374  0.07776024  0.09654702
  0.04348834  0.0177086   0.03372373 -0.03877991  0.10172553  0.06971465
 -0.06955674 -0.12222342]
epoch 1200 loss nan |dL/du| 5.431e-13
epoch 1200 sumw 1.000000
epoch 1200 weights [-0.07160262  0.11700858  0.12408468  0.02201765 -0.02151029  0.04433919
  0.12608652 -0.01081065  0.00885979  0.12182317  0.04719371  0.00812115
  0.08951059  0.02521918 -0.01056483  0.02833386  0.11933703 -0.00521459
  0.12172106 -0.11714811 -0.07889686  0.10198374  0.07776024  0.09654702
  0.04348834  0.0177086   0.03372373 -0.03877991  0.10172553  0.06971465
 -0.06955674 -0.12222342]
epoch 1300 loss nan |dL/du| 1.219e-14
epoch 1300 sumw 1.000000
epoch 1300 weights [-0.07160262  0.11700858  0.12408468  0.02201765 -0.02151029  0.04433919
  0.12608652 -0.01081065  0.00885979  0.12182317  0.04719371  0.00812115
  0.08951059  0.02521918 -0.01056483  0.02833386  0.11933703 -0.00521459
  0.12172106 -0.11714811 -0.07889686  0.10198374  0.07776024  0.09654702
  0.04348834  0.0177086   0.03372373 -0.03877991  0.10172553  0.06971465
 -0.06955674 -0.12222342]
epoch 1400 loss nan |dL/du| 9.930e-16
epoch 1400 sumw 1.000000
epoch 1400 weights [-0.07160262  0.11700858  0.12408468  0.02201765 -0.02151029  0.04433919
  0.12608652 -0.01081065  0.00885979  0.12182317  0.04719371  0.00812115
  0.08951059  0.02521918 -0.01056483  0.02833386  0.11933703 -0.00521459
  0.12172106 -0.11714811 -0.07889686  0.10198374  0.07776024  0.09654702
  0.04348834  0.0177086   0.03372373 -0.03877991  0.10172553  0.06971465
 -0.06955674 -0.12222342]
epoch 1500 loss nan |dL/du| 1.998e-15
epoch 1500 sumw 1.000000
epoch 1500 weights [-0.07160262  0.11700858  0.12408468  0.02201765 -0.02151029  0.04433919
  0.12608652 -0.01081065  0.00885979  0.12182317  0.04719371  0.00812115
  0.08951059  0.02521918 -0.01056483  0.02833386  0.11933703 -0.00521459
  0.12172106 -0.11714811 -0.07889686  0.10198374  0.07776024  0.09654702
  0.04348834  0.0177086   0.03372373 -0.03877991  0.10172553  0.06971465
 -0.06955674 -0.12222342]
epoch 1600 loss nan |dL/du| 1.961e-15
epoch 1600 sumw 1.000000
epoch 1600 weights [-0.07160262  0.11700858  0.12408468  0.02201765 -0.02151029  0.04433919
  0.12608652 -0.01081065  0.00885979  0.12182317  0.04719371  0.00812115
  0.08951059  0.02521918 -0.01056483  0.02833386  0.11933703 -0.00521459
  0.12172106 -0.11714811 -0.07889686  0.10198374  0.07776024  0.09654702
  0.04348834  0.0177086   0.03372373 -0.03877991  0.10172553  0.06971465
 -0.06955674 -0.12222342]
epoch 1700 loss nan |dL/du| 3.846e-16
epoch 1700 sumw 1.000000
epoch 1700 weights [-0.07160262  0.11700858  0.12408468  0.02201765 -0.02151029  0.04433919
  0.12608652 -0.01081065  0.00885979  0.12182317  0.04719371  0.00812115
  0.08951059  0.02521918 -0.01056483  0.02833386  0.11933703 -0.00521459
  0.12172106 -0.11714811 -0.07889686  0.10198374  0.07776024  0.09654702
  0.04348834  0.0177086   0.03372373 -0.03877991  0.10172553  0.06971465
 -0.06955674 -0.12222342]
epoch 1800 loss nan |dL/du| 1.506e-15
epoch 1800 sumw 1.000000
epoch 1800 weights [-0.07160262  0.11700858  0.12408468  0.02201765 -0.02151029  0.04433919
  0.12608652 -0.01081065  0.00885979  0.12182317  0.04719371  0.00812115
  0.08951059  0.02521918 -0.01056483  0.02833386  0.11933703 -0.00521459
  0.12172106 -0.11714811 -0.07889686  0.10198374  0.07776024  0.09654702
  0.04348834  0.0177086   0.03372373 -0.03877991  0.10172553  0.06971465
 -0.06955674 -0.12222342]
epoch 1900 loss nan |dL/du| 3.511e-16
epoch 1900 sumw 1.000000
epoch 1900 weights [-0.07160262  0.11700858  0.12408468  0.02201765 -0.02151029  0.04433919
  0.12608652 -0.01081065  0.00885979  0.12182317  0.04719371  0.00812115
  0.08951059  0.02521918 -0.01056483  0.02833386  0.11933703 -0.00521459
  0.12172106 -0.11714811 -0.07889686  0.10198374  0.07776024  0.09654702
  0.04348834  0.0177086   0.03372373 -0.03877991  0.10172553  0.06971465
 -0.06955674 -0.12222342]
epoch 2000 loss nan |dL/du| 6.933e-16
epoch 2000 sumw 1.000000
epoch 2000 weights [-0.07160262  0.11700858  0.12408468  0.02201765 -0.02151029  0.04433919
  0.12608652 -0.01081065  0.00885979  0.12182317  0.04719371  0.00812115
  0.08951059  0.02521918 -0.01056483  0.02833386  0.11933703 -0.00521459
  0.12172106 -0.11714811 -0.07889686  0.10198374  0.07776024  0.09654702
  0.04348834  0.0177086   0.03372373 -0.03877991  0.10172553  0.06971465
 -0.06955674 -0.12222342]
Saved final_weights.npy and loss_history_wifi.npy
p_raw min/med/max: -2.240e-02 / 8.638e-01 / 1.716e+00
p     min/med/max: 6.820e-01 / 1.216e+00 / 1.881e+00
sum(w): 1.000000
L1(w):  2.092616e+00
max|w|: 1.260865e-01
fraction p_raw < 0: 0.0002
Hessian eigenvalues are [1.34444424e-02 1.41069108e-02 1.49626365e-02 1.59270859e-02
 1.79128930e-02 1.87316956e-02 1.95017084e-02 2.00623109e-02
 2.07435988e-02 2.15283100e-02 2.41253058e-02 2.46184169e-02
 2.64828252e-02 2.83875327e-02 2.99482526e-02 3.38765413e-02
 3.67789329e-02 3.73202977e-02 3.94858800e-02 4.40843592e-02
 4.45998982e-02 4.54007099e-02 5.56324105e-02 5.72382485e-02
 6.56177017e-02 7.23108452e-02 7.55601228e-02 8.42218607e-02
 1.07643075e-01 1.67632705e-01 4.36187029e-01 3.24015704e+01]
All done.
