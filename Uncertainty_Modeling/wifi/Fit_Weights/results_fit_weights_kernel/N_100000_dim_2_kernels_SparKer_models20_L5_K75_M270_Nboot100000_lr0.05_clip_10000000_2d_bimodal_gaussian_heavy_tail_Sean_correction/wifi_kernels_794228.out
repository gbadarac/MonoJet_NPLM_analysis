Using folder_path = /work/gbadarac/MonoJet_NPLM/MonoJet_NPLM_analysis/Train_Ensembles/Train_Models/Sparker_kernels/EstimationKernels_outputs/2_dim/2d_bimodal_gaussian_heavy_tail/N_100000_dim_2_kernels_SparKer_models20_L5_K75_M270_Nboot100000_lr0.05_clip_10000000
Storing WiFi fit results in: /work/gbadarac/MonoJet_NPLM/MonoJet_NPLM_analysis/Uncertainty_Modeling/wifi/Fit_Weights/results_fit_weights_kernel/N_100000_dim_2_kernels_SparKer_models20_L5_K75_M270_Nboot100000_lr0.05_clip_10000000_2d_bimodal_gaussian_heavy_tail_Sean_correction
Loaded target data: (100000, 2)
Precomputing model_probs on CPU ...
model_probs stats: min 2.1394534041273488e-14 max 1.8003042606422504 finite True
model_probs_cpu computed: shape=(100000, 20)
epoch 100 loss -1.996034e+02 |dL/dw| 4.472e+00
epoch 100 |g_proj| 2.140e-05
epoch 100 loss -199.603355 weights [-9.95001878 -9.94994985 -9.94985799 -9.94991131 -9.95029376 -9.94989693
 -9.94998238 -9.94985396 -9.94983191 -9.94979022 -9.95020539 -9.95012681
 -9.95026843 -9.95023489 -9.95002906 -9.94997762 -9.94989856 -9.9500929
 -9.94983316 -9.94993656] sumw -198.999990
epoch 100 loss -199.603355 sumw_raw -198.999990 sumw_eff 1.000000
w_eff [0.0500001  0.04999975 0.04999929 0.04999956 0.05000148 0.04999948
 0.04999991 0.04999927 0.04999916 0.04999895 0.05000103 0.05000064
 0.05000135 0.05000118 0.05000015 0.04999989 0.04999949 0.05000047
 0.04999916 0.04999968]
epoch 200 loss -3.996034e+02 |dL/dw| 4.472e+00
epoch 200 |g_proj| 1.062e-05
epoch 200 loss -399.603352 weights [-19.95003333 -19.94991095 -19.949748   -19.94984257 -19.95052252
 -19.94981706 -19.94996869 -19.94974086 -19.94970177 -19.9496279
 -19.95036513 -19.95022532 -19.95047738 -19.95041765 -19.95005158
 -19.94996025 -19.94981994 -19.95016502 -19.94970399 -19.94988737] sumw -398.999987
epoch 200 loss -399.603352 sumw_raw -398.999987 sumw_eff 1.000000
w_eff [0.05000009 0.04999978 0.04999937 0.04999961 0.05000131 0.04999954
 0.04999992 0.04999935 0.04999925 0.04999907 0.05000092 0.05000057
 0.0500012  0.05000105 0.05000013 0.0499999  0.04999955 0.05000042
 0.04999926 0.04999972]
epoch 300 loss -5.996033e+02 |dL/dw| 4.472e+00
epoch 300 |g_proj| 7.063e-06
epoch 300 loss -599.603349 weights [-29.95004273 -29.94988568 -29.94967663 -29.94979795 -29.95067088
 -29.94976522 -29.94995977 -29.94966747 -29.94961733 -29.94952259
 -29.95046873 -29.95028919 -29.9506129  -29.95053617 -29.95006616
 -29.94994894 -29.94976892 -29.95021177 -29.94962017 -29.94985542] sumw -598.999985
epoch 300 loss -599.603349 sumw_raw -598.999985 sumw_eff 1.000000
w_eff [0.05000007 0.04999981 0.04999946 0.04999966 0.05000112 0.04999961
 0.04999993 0.04999945 0.04999936 0.0499992  0.05000078 0.05000048
 0.05000102 0.0500009  0.05000011 0.04999992 0.04999962 0.05000035
 0.04999937 0.04999976]
epoch 400 loss -7.996033e+02 |dL/dw| 4.472e+00
epoch 400 |g_proj| 5.291e-06
epoch 400 loss -799.603346 weights [-39.95004962 -39.94986707 -39.94962412 -39.9497651  -39.95077997
 -39.94972708 -39.94995319 -39.94961348 -39.94955522 -39.94944513
 -39.95054488 -39.95033613 -39.95071253 -39.95062331 -39.95007685
 -39.9499406  -39.94973137 -39.95024613 -39.94955852 -39.9498319 ] sumw -798.999982
epoch 400 loss -799.603346 sumw_raw -798.999982 sumw_eff 1.000000
w_eff [0.05000006 0.04999983 0.04999953 0.04999971 0.05000098 0.04999966
 0.04999994 0.04999952 0.04999944 0.04999931 0.05000068 0.05000042
 0.05000089 0.05000078 0.0500001  0.04999993 0.04999966 0.05000031
 0.04999945 0.04999979]
epoch 500 loss -9.996033e+02 |dL/dw| 4.472e+00
epoch 500 |g_proj| 4.229e-06
epoch 500 loss -999.603344 weights [-49.95005499 -49.94985248 -49.94958298 -49.94973937 -49.95086537
 -49.94969718 -49.94994801 -49.94957118 -49.94950655 -49.94938445
 -49.95060449 -49.95037287 -49.95079053 -49.95069152 -49.9500852
 -49.94993404 -49.94970194 -49.95027301 -49.94951021 -49.94981346] sumw -998.999980
epoch 500 loss -999.603344 sumw_raw -998.999980 sumw_eff 1.000000
w_eff [0.05000006 0.04999985 0.04999958 0.04999974 0.05000087 0.0499997
 0.04999995 0.04999957 0.04999951 0.04999938 0.05000061 0.05000037
 0.05000079 0.05000069 0.05000009 0.04999993 0.0499997  0.05000027
 0.04999951 0.04999981]
epoch 600 loss -1.199603e+03 |dL/dw| 4.472e+00
epoch 600 |g_proj| 3.523e-06
epoch 600 loss -1199.603342 weights [-59.95005934 -59.94984059 -59.94954951 -59.94971842 -59.9509348
 -59.94967286 -59.94994379 -59.94953676 -59.94946696 -59.94933509
 -59.95065295 -59.95040273 -59.95085395 -59.95074698 -59.95009197
 -59.94992869 -59.949678   -59.95029485 -59.94947092 -59.94979845] sumw -1198.999978
epoch 600 loss -1199.603342 sumw_raw -1198.999978 sumw_eff 1.000000
w_eff [0.05000005 0.04999987 0.04999963 0.04999977 0.05000078 0.04999973
 0.04999995 0.04999961 0.04999956 0.04999945 0.05000055 0.05000034
 0.05000071 0.05000062 0.05000008 0.04999994 0.04999973 0.05000025
 0.04999956 0.04999983]
epoch 700 loss -1.399603e+03 |dL/dw| 4.472e+00
epoch 700 |g_proj| 3.018e-06
epoch 700 loss -1399.603340 weights [-69.95006295 -69.94983066 -69.94952157 -69.94970093 -69.95099269
 -69.94965255 -69.94994024 -69.94950804 -69.94943393 -69.9492939
 -69.95069335 -69.95042761 -69.95090682 -69.95079321 -69.9500976
 -69.94992422 -69.94965801 -69.95031304 -69.94943813 -69.94978592] sumw -1398.999975
epoch 700 loss -1399.603340 sumw_raw -1398.999975 sumw_eff 1.000000
w_eff [0.05000005 0.04999988 0.04999966 0.04999979 0.05000071 0.04999975
 0.04999996 0.04999965 0.0499996  0.0499995  0.0500005  0.05000031
 0.05000065 0.05000057 0.05000007 0.04999995 0.04999976 0.05000022
 0.0499996  0.04999985]
epoch 800 loss -1.599603e+03 |dL/dw| 4.472e+00
epoch 800 |g_proj| 2.640e-06
epoch 800 loss -1599.603337 weights [-79.950066   -79.94982221 -79.94949785 -79.94968607 -79.95104182
 -79.9496353  -79.94993722 -79.94948364 -79.94940587 -79.94925893
 -79.95072764 -79.95044872 -79.95095169 -79.95083245 -79.95010237
 -79.9499204  -79.94964103 -79.95032848 -79.94941027 -79.94977526] sumw -1598.999973
epoch 800 loss -1599.603337 sumw_raw -1598.999973 sumw_eff 1.000000
w_eff [0.05000004 0.04999989 0.04999969 0.0499998  0.05000065 0.04999977
 0.04999996 0.04999968 0.04999963 0.04999954 0.05000046 0.05000028
 0.0500006  0.05000052 0.05000006 0.04999995 0.04999978 0.05000021
 0.04999963 0.04999986]
epoch 900 loss -1.799603e+03 |dL/dw| 4.472e+00
epoch 900 |g_proj| 2.346e-06
epoch 900 loss -1799.603335 weights [-89.95006861 -89.94981493 -89.94947741 -89.94967327 -89.95108409
 -89.94962044 -89.9499346  -89.94946263 -89.94938171 -89.94922881
 -89.95075712 -89.95046688 -89.9509903  -89.9508662  -89.95010646
 -89.9499171  -89.9496264  -89.95034175 -89.94938629 -89.94976607] sumw -1798.999971
epoch 900 loss -1799.603335 sumw_raw -1798.999971 sumw_eff 1.000000
w_eff [0.05000004 0.0499999  0.04999971 0.04999982 0.0500006  0.04999979
 0.04999996 0.0499997  0.04999966 0.04999957 0.05000042 0.05000026
 0.05000055 0.05000048 0.05000006 0.04999995 0.04999979 0.05000019
 0.04999966 0.04999987]
epoch 1000 loss -1.999603e+03 |dL/dw| 4.472e+00
epoch 1000 |g_proj| 2.111e-06
epoch 1000 loss -1999.603333 weights [-99.95007086 -99.94980859 -99.94945963 -99.94966212 -99.95112083
 -99.9496075  -99.94993232 -99.94944435 -99.94936069 -99.94920262
 -99.95078275 -99.95048265 -99.95102385 -99.95089553 -99.95011
 -99.94991422 -99.94961366 -99.95035327 -99.94936543 -99.94975807] sumw -1998.999969
epoch 1000 loss -1999.603333 sumw_raw -1998.999969 sumw_eff 1.000000
w_eff [0.05000004 0.04999991 0.04999973 0.04999983 0.05000056 0.0499998
 0.04999997 0.04999972 0.04999968 0.0499996  0.05000039 0.05000024
 0.05000051 0.05000045 0.05000006 0.04999996 0.04999981 0.05000018
 0.04999968 0.04999988]
epoch 1100 loss -2.199603e+03 |dL/dw| 4.472e+00
epoch 1100 |g_proj| 1.919e-06
epoch 1100 loss -2199.603331 weights [-109.95007283 -109.94980302 -109.94944403 -109.94965234 -109.95115303
 -109.94959615 -109.9499303  -109.94942831 -109.94934225 -109.94917964
 -109.9508052  -109.95049646 -109.95105325 -109.95092123 -109.95011309
 -109.94991169 -109.94960249 -109.95036336 -109.94934712 -109.94975105] sumw -2198.999967
epoch 1100 loss -2199.603331 sumw_raw -2198.999967 sumw_eff 1.000000
w_eff [0.05000003 0.04999991 0.04999975 0.04999984 0.05000053 0.04999982
 0.04999997 0.04999974 0.0499997  0.04999963 0.05000037 0.05000023
 0.05000048 0.05000042 0.05000005 0.04999996 0.04999982 0.05000017
 0.0499997  0.04999989]
epoch 1200 loss -2.399603e+03 |dL/dw| 4.472e+00
epoch 1200 |g_proj| 1.759e-06
epoch 1200 loss -2399.603329 weights [-119.95007455 -119.94979809 -119.94943026 -119.94964369 -119.95118143
 -119.94958612 -119.94992851 -119.94941415 -119.94932596 -119.94915935
 -119.95082501 -119.95050864 -119.95107918 -119.9509439  -119.95011581
 -119.94990944 -119.94959262 -119.95037225 -119.94933096 -119.94974483] sumw -2398.999965
epoch 1200 loss -2399.603329 sumw_raw -2398.999965 sumw_eff 1.000000
w_eff [0.05000003 0.04999992 0.04999976 0.04999985 0.05000049 0.04999983
 0.04999997 0.04999976 0.04999972 0.04999965 0.05000034 0.05000021
 0.05000045 0.05000039 0.05000005 0.04999996 0.04999983 0.05000016
 0.04999972 0.04999989]
epoch 1300 loss -2.599603e+03 |dL/dw| 4.472e+00
epoch 1300 |g_proj| 1.624e-06
epoch 1300 loss -2599.603327 weights [-129.95007607 -129.9497937  -129.94941802 -129.94963601 -129.95120662
 -129.94957721 -129.94992691 -129.94940157 -129.9493115  -129.94914133
 -129.95084258 -129.95051944 -129.95110219 -129.95096401 -129.95011821
 -129.94990743 -129.94958384 -129.95038013 -129.9493166  -129.94973931] sumw -2598.999963
epoch 1300 loss -2599.603327 sumw_raw -2598.999963 sumw_eff 1.000000
w_eff [0.05000003 0.04999992 0.04999978 0.04999986 0.05000046 0.04999984
 0.04999997 0.04999977 0.04999974 0.04999967 0.05000032 0.0500002
 0.05000042 0.05000037 0.05000005 0.04999997 0.04999984 0.05000015
 0.04999974 0.0499999 ]
epoch 1400 loss -2.799603e+03 |dL/dw| 4.472e+00
epoch 1400 |g_proj| 1.508e-06
epoch 1400 loss -2799.603325 weights [-139.95007742 -139.94978978 -139.94940709 -139.94962915 -139.95122908
 -139.94956925 -139.94992547 -139.94939034 -139.94929859 -139.94912526
 -139.95085823 -139.95052906 -139.95112269 -139.95098193 -139.95012033
 -139.94990562 -139.94957601 -139.95038715 -139.94930379 -139.94973437] sumw -2798.999961
epoch 1400 loss -2799.603325 sumw_raw -2798.999961 sumw_eff 1.000000
w_eff [0.05000003 0.04999993 0.04999979 0.04999987 0.05000044 0.04999985
 0.04999997 0.04999978 0.04999975 0.04999969 0.05000031 0.05000019
 0.0500004  0.05000035 0.05000004 0.04999997 0.04999985 0.05000014
 0.04999975 0.04999991]
epoch 1500 loss -2.999603e+03 |dL/dw| 4.472e+00
epoch 1500 |g_proj| 1.407e-06
epoch 1500 loss -2999.603323 weights [-149.95007861 -149.94978626 -149.94939731 -149.949623   -149.95124916
 -149.94956212 -149.94992417 -149.94938028 -149.94928703 -149.94911086
 -149.95087222 -149.95053765 -149.95114103 -149.95099796 -149.95012223
 -149.949904   -149.94956899 -149.95039342 -149.94929231 -149.94972995] sumw -2998.999959
epoch 1500 loss -2999.603323 sumw_raw -2998.999959 sumw_eff 1.000000
w_eff [0.05000003 0.04999993 0.0499998  0.04999987 0.05000042 0.04999985
 0.04999998 0.04999979 0.04999976 0.0499997  0.05000029 0.05000018
 0.05000038 0.05000033 0.05000004 0.04999997 0.04999986 0.05000013
 0.04999976 0.04999991]
epoch 1600 loss -3.199603e+03 |dL/dw| 4.472e+00
epoch 1600 |g_proj| 1.319e-06
epoch 1600 loss -3199.603321 weights [-159.95007967 -159.94978308 -159.94938851 -159.94961746 -159.95126719
 -159.9495557  -159.94992299 -159.94937123 -159.94927663 -159.94909792
 -159.95088478 -159.95054536 -159.95115749 -159.95101235 -159.95012392
 -159.94990253 -159.94956267 -159.95039904 -159.949282   -159.94972596] sumw -3198.999956
epoch 1600 loss -3199.603321 sumw_raw -3198.999956 sumw_eff 1.000000
w_eff [0.05000003 0.04999993 0.04999981 0.04999988 0.0500004  0.04999986
 0.04999998 0.0499998  0.04999977 0.04999972 0.05000028 0.05000017
 0.05000036 0.05000032 0.05000004 0.04999997 0.04999986 0.05000013
 0.04999978 0.04999992]
epoch 1700 loss -3.399603e+03 |dL/dw| 4.472e+00
epoch 1700 |g_proj| 1.241e-06
epoch 1700 loss -3399.603319 weights [-169.95008061 -169.94978022 -169.94938057 -169.94961247 -169.95128342
 -169.94954991 -169.94992192 -169.94936307 -169.94926726 -169.94908625
 -169.95089609 -169.9505523  -169.95117231 -169.95102529 -169.95012544
 -169.9499012  -169.94955697 -169.95040409 -169.94927269 -169.94972236] sumw -3398.999954
epoch 1700 loss -3399.603319 sumw_raw -3398.999954 sumw_eff 1.000000
w_eff [0.05000002 0.04999994 0.04999982 0.04999989 0.05000038 0.04999987
 0.04999998 0.04999981 0.04999979 0.04999973 0.05000026 0.05000016
 0.05000035 0.0500003  0.05000004 0.04999997 0.04999987 0.05000012
 0.04999979 0.04999992]
epoch 1800 loss -3.599603e+03 |dL/dw| 4.472e+00
epoch 1800 |g_proj| 1.172e-06
epoch 1800 loss -3599.603317 weights [-179.95008146 -179.94977762 -179.94937339 -179.94960795 -179.95129807
 -179.94954468 -179.94992095 -179.94935569 -179.94925879 -179.94907571
 -179.95090629 -179.95055855 -179.95118568 -179.95103698 -179.95012679
 -179.94989999 -179.94955181 -179.95040864 -179.94926428 -179.94971909] sumw -3598.999952
epoch 1800 loss -3599.603317 sumw_raw -3598.999952 sumw_eff 1.000000
w_eff [0.05000002 0.04999994 0.04999983 0.04999989 0.05000036 0.04999987
 0.04999998 0.04999982 0.04999979 0.04999974 0.05000025 0.05000016
 0.05000033 0.05000029 0.05000004 0.04999997 0.04999988 0.05000011
 0.0499998  0.04999992]
epoch 1900 loss -3.799603e+03 |dL/dw| 4.472e+00
epoch 1900 |g_proj| 1.111e-06
epoch 1900 loss -3799.603315 weights [-189.95008221 -189.94977525 -189.94936689 -189.94960384 -189.95131132
 -189.94953993 -189.94992005 -189.94934901 -189.94925111 -189.94906615
 -189.95091551 -189.9505642  -189.95119777 -189.95104754 -189.95012801
 -189.94989888 -189.94954714 -189.95041275 -189.94925666 -189.94971613] sumw -3798.999950
epoch 1900 loss -3799.603315 sumw_raw -3798.999950 sumw_eff 1.000000
w_eff [0.05000002 0.04999994 0.04999983 0.0499999  0.05000035 0.04999988
 0.04999998 0.04999983 0.0499998  0.04999975 0.05000024 0.05000015
 0.05000032 0.05000028 0.05000003 0.04999997 0.04999988 0.05000011
 0.0499998  0.04999993]
epoch 2000 loss -3.999603e+03 |dL/dw| 4.472e+00
epoch 2000 |g_proj| 1.055e-06
epoch 2000 loss -3999.603313 weights [-199.95008288 -199.9497731  -199.94936098 -199.94960011 -199.95132333
 -199.94953561 -199.94991924 -199.94934293 -199.94924413 -199.94905748
 -199.95092386 -199.95056932 -199.95120873 -199.95105712 -199.95012911
 -199.94989787 -199.94954289 -199.95041647 -199.94924973 -199.94971344] sumw -3998.999948
epoch 2000 loss -3999.603313 sumw_raw -3998.999948 sumw_eff 1.000000
w_eff [0.05000002 0.04999994 0.04999984 0.0499999  0.05000033 0.04999988
 0.04999998 0.04999984 0.04999981 0.04999976 0.05000023 0.05000014
 0.0500003  0.05000026 0.05000003 0.04999998 0.04999989 0.0500001
 0.04999981 0.04999993]
Saved final_weights.npy and loss_history_wifi.npy
All done.
